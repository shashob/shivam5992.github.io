
<!DOCTYPE html>
		<html lang="en"><html>
		<head>
			<meta charset="utf-8" />
			<meta http-equiv="X-UA-Compatible" content="IE=edge" />
			<title>Notes: Neural Networks - 2, Backpropagation Algorithm - Shivam Bansal's Blog</title>
			<meta name="description" content="" />
			<meta name="HandheldFriendly" content="True" />
			<meta name="viewport" content="width=device-width, initial-scale=1.0" />
			<link rel="shortcut icon" href="../../img/SB.png">
			<link rel="canonical" href="http://shivambansal.com/blog/neural_network_2/" />
			<meta name="referrer" content="origin" />
			<meta property="og:site_name" content="Shivam Bansal" />
			<meta property="og:type" content="article" />
			<meta property="og:title" content='Notes: Neural Networks - 2, Backpropagation Algorithm' />
			<meta property="og:description" content='In backpropagation algorithm, gradient of our cost function (delta change in cost) is calculated.' />
			<meta property="og:url" content='http://shivambansal.com/blog/data-mining/' />
			<meta property="og:image" content="../../img/post-bg.jpg" />
			<meta property="article:published_time" content='Dec 10, 2015' />
			<meta property="article:tag" content="" />
			<meta property="article:tag" content="" />
			<link href="../../css/bootstrap.min.css" rel="stylesheet">
			<link href="../../css/clean-blog.css" rel="stylesheet">
			<link href='http://fonts.googleapis.com/css?family=Open+Sans:300,400' rel='stylesheet' type='text/css'>
		</head>

		<body>
			<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
				<div class="container-fluid">
					<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
						<ul class="nav navbar-nav navbar-right">
							<li>
								<a href="../../index.html">Home</a>
							</li>
							<li>
								<a href="../../about/">About</a>
							</li>

						</ul>
					</div>
				</div>
			</nav>

			<header class="intro-header">
				<div class="container">
					<div class="row">
						<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
							<div class="post-heading">
								<h1>Understanding How Backpropagation Algorithm works - Neural Networks 2</h1>
								<span class="sub-desc">Posted on Jan 14, 2016</span>
							</div>
						</div>
					</div>
				</div>
			</header>

			<article>
				<div class="container">
					<div class="row">
						<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 arttext">
							
							<p>
								In the last article about neural networks, I discussed the topics - perceptron, sigmoid neurons, architecture of a neural network and learning of a neural network - gradient descent. We also applied a back propagation algorithm using Stochastic gradient descent in order to train the network. In this article, I will discuss about backpropagation algorithm in detail.
							</p>

							<p>
								Quick Recap - We had built a neural network with one hidden layer, using sigmoid activation functions. Each training example (input feature vectors) is passed as input to the network. These are feedforward in the network using non linear sigmoid activation function. Output at each node is given as sigmoid function of (w. a’ + b), where w is the weight, a’ is the activation from previous layer and b is the bias vector. Now, the task is to train the network, hence the error term / loss / cost function is calculated using stochastic gradient descent (SGD) is used with backpropagation algorithm. In language of machine learning, training means the process of tuning the weights and bias variables so that error term is minimized. 
							</p>

							<p>
								What is Backpropagation Algorithm ? 
								<br><br>
								In backpropagation algorithm, gradient of the cost function (delta change in cost) is calculated at the final layer. This gradient (error) is back passed to previous layers, by which changes are made in current weights and biases (delta weights and delta biases are subtracted from original values). This process is iteratively performed until cost function reaches the minimum value. The results of backpropagation algorithms can be grasped with the fact that every delta change made at the node level, affects the output of the network. 

							</p>

							<p>
								How Backpropagation Algorithms work ?	
								<br><br>
								Since there are multiple cost functions, which are calculated for every training example. Final cost function can be computed as the average of all individual cost functions. Backpropagation works using four basic mathematical equations:

							</p>

							<div class="img-post">
								<img src="images/1.png" alt="poster">
							</div>

							<p>
								L: Final output layer <br>
								C: Final Cost Function <br>
								<br>

								the above equation states that the error of final layer can be computed using derivative of cost with respect of final activation as computed in output layer. The term signifies that how fast cost function changes with respect to the activations. This term is multiplied with sigmoid prime of input vectors of final layer which signifies, how fast an activation is changing due to change in inputs.  
							</p>

							<div class="img-post"><img src="images/2.png" alt="poster"></div>

							<p>
								The above equation states that the error of a layer can be written in terms of error of next layer. This generates back passes. The error of a layer is hence weight matrix of next layer times error of the layer, this is then multiplied using hadamard product with sigmoid prime of current layer inputs (current activation) 
							</p>


							<div class="img-post"><img src="images/3.png" alt="poster"></div>

							<p>Bias parameters can be computed using error of the layer</p>

							<div class="img-post"><img src="images/4.png" alt="poster"></div>

							<p>
								Weight parameters can be computed using error of the layer. Hence, the complete backpropagation can be summed up as:
							</p> 
							<p>
								1. Input the x - training example
							</p>
							<p>
								2. Feedforward the activations through each layer, and compute final activation.
								<br>
								input terms: z = w.a’ + b & activation function: sigmoid (z)
							</p>
							<p>	
								3. Calculate the error term of final layer: delta L, using equation , which can also be written as  ∇aC ⊙ σ′(zL)
							</p>
							<p>	
								4. Backpropagate the error using equation [2]  δl=((wl+1)Tδl+1)⊙σ′(zl)
							</p>
							<p>	
								5. Adjust weights and bias, using equation [3] and [4] 
							</p>

							<p>The complete code is available here, <a href="https://github.com/shivam5992/neural-networks-notes">Here</a></p>

							<!--  -->
							<br>
		                    <div id="disqus_thread"></div>
		                    <script type="text/javascript">
		                    /* * * CONFIGURATION VARIABLES * * */
		                    var disqus_shortname = 'shivambansal';

		                    /* * * DON'T EDIT BELOW THIS LINE * * */
		                    (function() {
		                        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		                        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		                        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
		                    })();
		                    </script>

						</div>
					</div>
				</div>
			</article>

			<hr>
			<footer>
				<div class="container">
					<div class="row">
						<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
							<p class="copyright text-muted">&copy; shivambansal.com 2017</p>
						</div>
					</div>
				</div>
			</footer>

			<script>
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
				(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
				m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
			ga('create', 'UA-45186276-1', 'shivambansal.com');
			ga('send', 'pageview');
			</script>
		</body>
		</html>